{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b68e327",
   "metadata": {},
   "source": [
    "# Model Desrciption\n",
    "The program downloads and preprocesses the Sign Language MNIST dataset, then builds, trains, and evaluates multiple neural network classifiers for recognizing hand-sign images. It trains both a dense baseline model and several convolutional neural networks with different optimizers, using early stopping to prevent overfitting. Training time and best validation accuracy are automatically logged, model performance is evaluated on a test set, results are summarized in a comparison table, and the trained models are saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1af67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for Dense Model...\n",
      "Epoch 1/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.3386 - loss: 2.2269 - val_accuracy: 0.5043 - val_loss: 1.7251\n",
      "Epoch 2/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6062 - loss: 1.2628 - val_accuracy: 0.5558 - val_loss: 1.3593\n",
      "Epoch 3/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7059 - loss: 0.9306 - val_accuracy: 0.5906 - val_loss: 1.2813\n",
      "Epoch 4/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7771 - loss: 0.7257 - val_accuracy: 0.6474 - val_loss: 1.0836\n",
      "Epoch 5/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8177 - loss: 0.5936 - val_accuracy: 0.6616 - val_loss: 1.0968\n",
      "Finished training Dense Model in 25.09s\n",
      "Best validation accuracy for Dense Model: 0.6616\n",
      "\n",
      "Dense model final evaluation - loss: 1.0836, accuracy: 0.6474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for CNN (adam)...\n",
      "Epoch 1/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 39ms/step - accuracy: 0.5465 - loss: 1.9981 - val_accuracy: 0.6669 - val_loss: 1.9172\n",
      "Epoch 2/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - accuracy: 0.8696 - loss: 0.7610 - val_accuracy: 0.8907 - val_loss: 0.6621\n",
      "Epoch 3/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9350 - loss: 0.4780 - val_accuracy: 0.9235 - val_loss: 0.4782\n",
      "Epoch 4/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9540 - loss: 0.3633 - val_accuracy: 0.9202 - val_loss: 0.4573\n",
      "Epoch 5/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 45ms/step - accuracy: 0.9592 - loss: 0.3261 - val_accuracy: 0.9235 - val_loss: 0.4481\n",
      "Finished training CNN (adam) in 93.72s\n",
      "Best validation accuracy for CNN (adam): 0.9235\n",
      "\n",
      "\n",
      "Starting training for CNN (sgd)...\n",
      "Epoch 1/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.3322 - loss: 2.9325 - val_accuracy: 0.4264 - val_loss: 2.6901\n",
      "Epoch 2/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 38ms/step - accuracy: 0.6122 - loss: 1.8536 - val_accuracy: 0.6491 - val_loss: 1.8423\n",
      "Epoch 3/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - accuracy: 0.7353 - loss: 1.4173 - val_accuracy: 0.8162 - val_loss: 1.2325\n",
      "Epoch 4/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 35ms/step - accuracy: 0.8027 - loss: 1.1738 - val_accuracy: 0.8819 - val_loss: 0.9803\n",
      "Epoch 5/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 36ms/step - accuracy: 0.8496 - loss: 0.9982 - val_accuracy: 0.8632 - val_loss: 0.9277\n",
      "Finished training CNN (sgd) in 82.44s\n",
      "Best validation accuracy for CNN (sgd): 0.8819\n",
      "\n",
      "\n",
      "Starting training for CNN (rmsprop)...\n",
      "Epoch 1/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - accuracy: 0.6005 - loss: 1.8611 - val_accuracy: 0.7276 - val_loss: 1.7337\n",
      "Epoch 2/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 38ms/step - accuracy: 0.8828 - loss: 0.7342 - val_accuracy: 0.8827 - val_loss: 0.6821\n",
      "Epoch 3/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.9328 - loss: 0.4715 - val_accuracy: 0.9046 - val_loss: 0.5397\n",
      "Epoch 4/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9468 - loss: 0.3680 - val_accuracy: 0.8984 - val_loss: 0.4963\n",
      "Epoch 5/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 37ms/step - accuracy: 0.9567 - loss: 0.3131 - val_accuracy: 0.8433 - val_loss: 0.6132\n",
      "Finished training CNN (rmsprop) in 84.25s\n",
      "Best validation accuracy for CNN (rmsprop): 0.9046\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison Table:\n",
      "           Model  Best Val Accuracy  Test Accuracy\n",
      "1     CNN (adam)           0.923452       0.923452\n",
      "3  CNN (rmsprop)           0.904629       0.898355\n",
      "2      CNN (sgd)           0.881902       0.863218\n",
      "0    Dense Model           0.661601       0.647379\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from functools import wraps\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# Decorator to log training\n",
    "def log_training(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        self = args[0]  # First arg is always the instance\n",
    "        print(f\"\\nStarting training for {self.model_name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        history = func(*args, **kwargs)\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        best_val_acc = self.best_val_acc\n",
    "        print(f\"Finished training {self.model_name} in {duration:.2f}s\")\n",
    "        print(f\"Best validation accuracy for {self.model_name}: {best_val_acc:.4f}\\n\")\n",
    "        return history\n",
    "    return wrapper\n",
    "\n",
    "# -----------------------\n",
    "# ASL Model Class\n",
    "class ASLModel:\n",
    "    def __init__(self, model_name=\"Model\", input_shape=(28,28,1), num_classes=26):\n",
    "        self.model = None\n",
    "        self.model_name = model_name\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.history = None\n",
    "        self.early_stop = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "\n",
    "    # -----------------------\n",
    "    def build_dense(self):\n",
    "        self.model = Sequential([\n",
    "            Flatten(input_shape=self.input_shape),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(self.num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        self.model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # -----------------------\n",
    "    def build_cnn(self, conv_layers=None, dense_layers=None, optimizer=\"adam\",\n",
    "                  use_dropout=False, use_batchnorm=False, l2_reg=0.0):\n",
    "        \"\"\"\n",
    "        Flexible CNN builder.\n",
    "        conv_layers: list of tuples (filters, kernel_size, pool_size)\n",
    "        dense_layers: list of integers (units)\n",
    "        \"\"\"\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        if conv_layers is None:\n",
    "            conv_layers = [(16, (3,3), (2,2)), (32, (3,3), (2,2))]\n",
    "        if dense_layers is None:\n",
    "            dense_layers = [64]\n",
    "\n",
    "        # Add convolutional layers\n",
    "        for i, (filters, kernel_size, pool_size) in enumerate(conv_layers):\n",
    "            if i == 0:\n",
    "                self.model.add(Conv2D(filters, kernel_size, activation=\"relu\",\n",
    "                                      input_shape=self.input_shape,\n",
    "                                      kernel_regularizer=l2(l2_reg) if l2_reg>0 else None))\n",
    "            else:\n",
    "                self.model.add(Conv2D(filters, kernel_size, activation=\"relu\",\n",
    "                                      kernel_regularizer=l2(l2_reg) if l2_reg>0 else None))\n",
    "            if use_batchnorm:\n",
    "                self.model.add(BatchNormalization())\n",
    "            self.model.add(MaxPooling2D(pool_size))\n",
    "\n",
    "        self.model.add(Flatten())\n",
    "\n",
    "        # Add dense layers\n",
    "        for units in dense_layers:\n",
    "            self.model.add(Dense(units, activation=\"relu\",\n",
    "                                 kernel_regularizer=l2(l2_reg) if l2_reg>0 else None))\n",
    "            if use_dropout:\n",
    "                self.model.add(Dropout(0.6))\n",
    "\n",
    "        # Output layer\n",
    "        self.model.add(Dense(self.num_classes, activation=\"softmax\"))\n",
    "\n",
    "        # Optimizer selection\n",
    "        if optimizer==\"adam\":\n",
    "            opt = Adam()\n",
    "        elif optimizer==\"sgd\":\n",
    "            opt = SGD()\n",
    "        elif optimizer==\"rmsprop\":\n",
    "            opt = RMSprop()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported optimizer\")\n",
    "\n",
    "        self.model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # -----------------------\n",
    "    @log_training\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=5, batch_size=64):\n",
    "        self.history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1,\n",
    "            callbacks=[self.early_stop]\n",
    "        )\n",
    "        return self.history\n",
    "\n",
    "    # -----------------------\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        loss, acc = self.model.evaluate(X_test, y_test, verbose=0)\n",
    "        return loss, acc\n",
    "\n",
    "    # Lambda property for best val accuracy\n",
    "    best_val_acc = property(lambda self: max(self.history.history[\"val_accuracy\"])\n",
    "                            if self.history and self.history.history[\"val_accuracy\"] else None)\n",
    "\n",
    "    # -----------------------\n",
    "    def save(self, path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        self.model.save(path)\n",
    "\n",
    "# -----------------------\n",
    "# Data Loading and Preprocessing\n",
    "path = kagglehub.dataset_download(\"datamunge/sign-language-mnist\")\n",
    "train_data = pd.read_csv(f\"{path}/sign_mnist_train.csv\")\n",
    "test_data = pd.read_csv(f\"{path}/sign_mnist_test.csv\")\n",
    "\n",
    "y_train = train_data[\"label\"].values\n",
    "y_test = test_data[\"label\"].values\n",
    "X_train = train_data.drop(\"label\", axis=1).values\n",
    "X_test = test_data.drop(\"label\", axis=1).values\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=26)\n",
    "y_test = to_categorical(y_test, num_classes=26)\n",
    "\n",
    "# -----------------------\n",
    "# Train Dense Model\n",
    "dense_model = ASLModel(\"Dense Model\")\n",
    "dense_model.build_dense()\n",
    "dense_model.train(X_train, y_train, X_test, y_test, epochs=5, batch_size=64)\n",
    "loss, acc = dense_model.evaluate(X_test, y_test)\n",
    "print(f\"Dense model final evaluation - loss: {loss:.4f}, accuracy: {acc:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# Train CNN Models with flexible architecture\n",
    "optimizers = [\"adam\", \"sgd\", \"rmsprop\"]\n",
    "cnn_models = {}\n",
    "for opt in optimizers:\n",
    "    cnn = ASLModel(f\"CNN ({opt})\")\n",
    "    cnn.build_cnn(\n",
    "        conv_layers=[(16,(3,3),(2,2)), (32,(3,3),(2,2))],  # Can customize later\n",
    "        dense_layers=[64],\n",
    "        optimizer=opt,\n",
    "        use_dropout=True,\n",
    "        use_batchnorm=True,\n",
    "        l2_reg=0.005\n",
    "    )\n",
    "    cnn.train(X_train, y_train, X_test, y_test, epochs=5, batch_size=64)\n",
    "    cnn_models[opt] = cnn\n",
    "\n",
    "# -----------------------\n",
    "# Automatic model comparison table\n",
    "import pandas as pd\n",
    "\n",
    "comparison = []\n",
    "# Dense model\n",
    "comparison.append({\n",
    "    \"Model\": dense_model.model_name,\n",
    "    \"Best Val Accuracy\": dense_model.best_val_acc,\n",
    "    \"Test Accuracy\": dense_model.evaluate(X_test, y_test)[1]\n",
    "})\n",
    "\n",
    "# CNN models\n",
    "for cnn in cnn_models.values():\n",
    "    comparison.append({\n",
    "        \"Model\": cnn.model_name,\n",
    "        \"Best Val Accuracy\": cnn.best_val_acc,\n",
    "        \"Test Accuracy\": cnn.evaluate(X_test, y_test)[1]\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison).sort_values(by=\"Best Val Accuracy\", ascending=False)\n",
    "print(\"\\nModel Comparison Table:\")\n",
    "print(df_comparison)\n",
    "\n",
    "# -----------------------\n",
    "# Save models\n",
    "dense_model.save(\"src/ASL-classifier-model/asl_dense_model.h5\")\n",
    "cnn_models[\"adam\"].save(\"src/ASL-classifier-model/asl_cnn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d5df2",
   "metadata": {},
   "source": [
    "# Summary of Changes\n",
    "\n",
    "The original procedural script was refactored into a modular, object-oriented pipeline that cleanly separates data handling, model construction, training, and evaluation. Training is now monitored with a decorator and early stopping to reduce overfitting, CNN architectures are fully configurable, and both dense and CNN models are evaluated consistently. The final version also automatically compares models and reports performance, making experimentation clearer, safer, and easier to extend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b0ebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dense Model\n",
      "============================================================\n",
      "\n",
      "Model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m1,690\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,428</span> (431.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,428\u001b[0m (431.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,426</span> (431.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,426\u001b[0m (431.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total parameters: 110,426\n",
      "Trainable parameters: 110,426\n",
      "Non-trainable parameters: 0.0\n",
      "\n",
      "Optimizer configuration:\n",
      "{'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "Test loss: 1.0836\n",
      "Test accuracy: 0.6474\n",
      "============================================================\n",
      "CNN Model (Adam)\n",
      "============================================================\n",
      "\n",
      "Model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m51,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)             │         \u001b[38;5;34m1,690\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,948</span> (226.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,948\u001b[0m (226.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,850</span> (225.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,850\u001b[0m (225.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total parameters: 57,946\n",
      "Trainable parameters: 57,850\n",
      "Non-trainable parameters: 96\n",
      "\n",
      "Optimizer configuration:\n",
      "{'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "\n",
      "Test loss: 0.4481\n",
      "Test accuracy: 0.9235\n",
      "\n",
      "Model inspection complete.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------\n",
    "# Load saved models\n",
    "dense_model = load_model(\"src/ASL-classifier-model/asl_dense_model.h5\")\n",
    "cnn_model = load_model(\"src/ASL-classifier-model/asl_cnn_model.h5\")\n",
    "\n",
    "models = {\n",
    "    \"Dense Model\": dense_model,\n",
    "    \"CNN Model (Adam)\": cnn_model\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# Inspect each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{name}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Architecture\n",
    "    print(\"\\nModel summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Parameter counts\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = np.sum([np.prod(w.shape) for w in model.trainable_weights])\n",
    "    non_trainable_params = np.sum([np.prod(w.shape) for w in model.non_trainable_weights])\n",
    "\n",
    "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Non-trainable parameters: {non_trainable_params:,}\")\n",
    "\n",
    "    # Optimizer details\n",
    "    optimizer = model.optimizer\n",
    "    print(\"\\nOptimizer configuration:\")\n",
    "    print(optimizer.get_config())\n",
    "\n",
    "    # Evaluation on test data\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nTest loss: {loss:.4f}\")\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nModel inspection complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
